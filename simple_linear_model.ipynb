{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simple_linear_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPFl/6Autq9jSuaM7UY2bCz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/petersim1/deep-image-prior/blob/master/simple_linear_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TW2YgPJD79c"
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNsfrXH6D_0Q",
        "outputId": "fa0d139e-d753-427a-c6a6-bce9264d5ebf"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sO3-AaxdEBpi"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrUBwt95ETEp",
        "outputId": "0d3031ed-bd61-4e7b-d4c0-aa30d64a45b1"
      },
      "source": [
        "cd drive/MyDrive/Semester\\ 3/Bayesian\\ ML/Project/flikr8k_sized"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Semester 3/Bayesian ML/Project/flikr8k_sized\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axm4G2gHmTOb"
      },
      "source": [
        "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daaGeaSmEHFc"
      },
      "source": [
        "images = []\n",
        "for ind, f in enumerate(os.listdir('.')):\n",
        "  if f != '.DS_Store':\n",
        "    im = Image.open('./'+f) \n",
        "    im = np.asarray(im)\n",
        "    images.append(im)\n",
        "  if ind == 5:\n",
        "    break"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GggGMaenU_q",
        "outputId": "c2225368-11e9-42e5-dfe5-a8d1157995e2"
      },
      "source": [
        "for i in images:\n",
        "  print(i.shape, np.max(i))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(333, 500, 3) 255\n",
            "(333, 500, 3) 255\n",
            "(333, 500, 3) 255\n",
            "(333, 500, 3) 255\n",
            "(333, 500, 3) 255\n",
            "(333, 500, 3) 255\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNW4d_QQEKw6"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import MNIST\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YOp9sj8EZfU"
      },
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, images, mode='train'):\n",
        "        split = int(len(images)*.8)\n",
        "        if mode == 'train':\n",
        "            self.images = images[:split]\n",
        "        elif mode == 'val':\n",
        "            self.images = images[split:]\n",
        "            \n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        im = torch.from_numpy(np.moveaxis(images[idx], -1, 0)).float()\n",
        "        label = torch.Tensor([0])\n",
        "        return im, label"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-BsUxa8EgL7"
      },
      "source": [
        "train_dataset = ImageDataset(images, 'train')\n",
        "valid_dataset = ImageDataset(images, 'val')\n",
        "\n",
        "train_loader = DataLoader(dataset = train_dataset, batch_size = 1, shuffle = True)\n",
        "val_loader = DataLoader(dataset = valid_dataset, batch_size = 1, shuffle = False)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P16he5m0JmRG"
      },
      "source": [
        "# Reconstruction + KL divergence losses summed over all elements and batch\n",
        "\n",
        "def loss_function(x_hat, x, mu, logvar):\n",
        "    BCE = nn.functional.binary_cross_entropy(\n",
        "        x_hat, x.view(-1, 499500), reduction='sum'\n",
        "    )\n",
        "    KLD = 0.5 * torch.sum(logvar.exp() - logvar - 1 + mu.pow(2))\n",
        "\n",
        "    return BCE + KLD"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7bSrsRuEkFF"
      },
      "source": [
        "class bigVAE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(499500, 200), #500x333x3\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(200, 50),\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(25, 200),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(200, 499500),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def reparameterise(self, mu, logvar):\n",
        "        if self.training:\n",
        "            std = logvar.mul(0.5).exp_()\n",
        "            eps = std.data.new(std.size()).normal_()\n",
        "            return eps.mul(std).add_(mu)\n",
        "        else:\n",
        "            return mu\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu_logvar = self.encoder(x.view(-1, 499500)).view(-1, 2, 25)\n",
        "        mu = mu_logvar[:, 0, :]\n",
        "        logvar = mu_logvar[:, 1, :]\n",
        "        z = self.reparameterise(mu, logvar)\n",
        "        return self.decoder(z), mu, logvar\n",
        "\n",
        "    def initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "#             print(m)\n",
        "            if isinstance(m, Sequential):\n",
        "                for elem in m:\n",
        "                    if isinstance(elem, Linear):\n",
        "                        torch.nn.init.zeros_(elem.weight)\n",
        "            elif isinstance(m, Linear):\n",
        "                torch.nn.init.zeros_(elem.weight)\n",
        "\n",
        "device = torch.device(\"cpu\")#torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = bigVAE().to(device)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCrdLghoP4bv",
        "outputId": "08c272c4-469a-4ef4-c89d-6c8b906ea540"
      },
      "source": [
        "print(device)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rn8NXai8K3d7"
      },
      "source": [
        "learning_rate = 1e-3\n",
        "\n",
        "optimizer = torch.optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=learning_rate,\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALKPFpY6EolW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "outputId": "17df7f4d-12db-460c-a2d1-5898d779eea7"
      },
      "source": [
        "# Training and testing the VAE\n",
        "\n",
        "epochs = 10\n",
        "codes = dict(μ=list(), logσ2=list())\n",
        "for epoch in range(0, epochs + 1):\n",
        "    # Training\n",
        "    if epoch > 0:  # test untrained net first\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for x, _ in train_loader:\n",
        "            x = x.to(device)\n",
        "            # ===================forward=====================\n",
        "            x_hat, mu, logvar = model(x)\n",
        "            print(torch.max(x_hat), torch.max(x))\n",
        "            loss = loss_function(x_hat, x, mu, logvar)\n",
        "            train_loss += loss.item()\n",
        "            # ===================backward====================\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        # ===================log========================\n",
        "        print(f'====> Epoch: {epoch} Average loss: {train_loss / len(train_loader.dataset):.4f}')\n",
        "    \n",
        "    # Testing\n",
        "    \n",
        "    means, logvars = list(), list()\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        test_loss = 0\n",
        "        for x, y in val_loader:\n",
        "            x = x.to(device)\n",
        "            # ===================forward=====================\n",
        "            x_hat, mu, logvar = model(x)\n",
        "            test_loss += loss_function(x_hat, x, mu, logvar).item()\n",
        "            # =====================log=======================\n",
        "            means.append(mu.detach())\n",
        "            logvars.append(logvar.detach())\n",
        "    # ===================log========================\n",
        "    # codes['μ'].append(torch.cat(means))\n",
        "    # codes['logσ2'].append(torch.cat(logvars))\n",
        "    test_loss /= len(val_loader.dataset)\n",
        "    print(f'====> Test set loss: {test_loss:.4f}')\n",
        "    # display_images(x, x_hat, 1, f'Epoch {epoch}')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "====> Test set loss: 143707757053109137978603601920.0000\n",
            "tensor(1., grad_fn=<MaxBackward1>) tensor(255.)\n",
            "tensor(1., grad_fn=<MaxBackward1>) tensor(255.)\n",
            "tensor(1., grad_fn=<MaxBackward1>) tensor(255.)\n",
            "tensor(1., grad_fn=<MaxBackward1>) tensor(255.)\n",
            "====> Epoch: 1 Average loss: 19440054319225333031956300594937856.0000\n",
            "====> Test set loss: inf\n",
            "tensor(nan, grad_fn=<MaxBackward1>) tensor(255.)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-95b886aba8c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mx_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m# ===================backward====================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-c373f04eb597>\u001b[0m in \u001b[0;36mloss_function\u001b[0;34m(x_hat, x, mu, logvar)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     BCE = nn.functional.binary_cross_entropy(\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mx_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m499500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     )\n\u001b[1;32m      7\u001b[0m     \u001b[0mKLD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2525\u001b[0m     return torch._C._nn.binary_cross_entropy(\n\u001b[0;32m-> 2526\u001b[0;31m         input, target, weight, reduction_enum)\n\u001b[0m\u001b[1;32m   2527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: all elements of input should be between 0 and 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oy4EnUqFIVZp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}