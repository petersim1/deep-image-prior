{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "conv_vae.ipynb",
      "provenance": [],
      "mount_file_id": "1q5OUYY0LWygKLsKfZguw9MfJCNR7vFFG",
      "authorship_tag": "ABX9TyNKncwLHthuDFpk4XkZjJEb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/petersim1/deep-image-prior/blob/master/conv_vae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "md8Yhz6Uc-Im"
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZy8EmTFlqer",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40ddb904-d4a4-4252-dca0-7dbac2f764e6"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IDyqUgOmh9B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "714350f3-403f-4330-8d15-a0fe6984a008"
      },
      "source": [
        "cd drive/MyDrive/Semester\\ 3/Bayesian\\ ML/Project/flikr8k_sized"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Semester 3/Bayesian ML/Project/flikr8k_sized\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qYJusQQepXf"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import MNIST\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4fNlRBLWBPd"
      },
      "source": [
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xItezf8ffSwZ"
      },
      "source": [
        "images = []\n",
        "for f in os.listdir('.'):\n",
        "  if f != '.DS_Store':\n",
        "    im = Image.open('./'+f) \n",
        "    im = np.asarray(im)\n",
        "    images.append(im)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4dSjp2RhRJV"
      },
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, images, mode='train'):\n",
        "        if mode == 'train':\n",
        "            self.images = images[:1219]\n",
        "        elif mode == 'val':\n",
        "            self.images = images[1219:]\n",
        "            \n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        im = torch.from_numpy(np.moveaxis(images[idx], -1, 0)).float()\n",
        "        return  im"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5E7OrEbioGC"
      },
      "source": [
        "train_dataset = ImageDataset(images, 'train')\n",
        "valid_dataset = ImageDataset(images, 'val')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfsQ4Maliusw"
      },
      "source": [
        "train_loader = DataLoader(dataset = train_dataset, batch_size = 1, shuffle = True)\n",
        "val_loader = DataLoader(dataset = valid_dataset, batch_size = 1, shuffle = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPwfYUv0ixAf"
      },
      "source": [
        "def loss_function(recon_x, x, mu, logvar):\n",
        "  print('Input max: {}, Recon max: {}'.format(torch.max(x), torch.max(recon_x)))\n",
        "  BCE = F.binary_cross_entropy(recon_x, x, size_average=False)\n",
        "  KLD = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "  return BCE + KLD, BCE, KLD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Te0TzSlgizo6"
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)\n",
        "\n",
        "class UnFlatten(nn.Module):\n",
        "    def forward(self, input, size=26624):\n",
        "        return input.view(input.size(0), size, 1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4LIwp2Ci2p0"
      },
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self, image_channels=3, h_dim=26624, z_dim=32):\n",
        "        super(VAE, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(image_channels, 32, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            Flatten()\n",
        "        )\n",
        "        \n",
        "        self.fc1 = nn.Linear(h_dim, z_dim) #26624 = 13x8x256\n",
        "        self.fc2 = nn.Linear(h_dim, z_dim)\n",
        "        self.fc3 = nn.Linear(z_dim, h_dim)\n",
        "        \n",
        "        self.decoder = nn.Sequential(\n",
        "            UnFlatten(),\n",
        "            nn.ConvTranspose2d(h_dim, 128, kernel_size=(6,9), stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=(6,9), stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=(6,9), stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 16, kernel_size=(6,9), stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(16, 8, kernel_size=(6,9), stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(8, image_channels, kernel_size=(23,4), stride=2),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "        \n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = logvar.mul(0.5).exp_().to(device)\n",
        "        # return torch.normal(mu, std)\n",
        "        esp = torch.randn(*mu.size()).to(device)\n",
        "        z = mu.to(device) + std * esp\n",
        "        return z\n",
        "    \n",
        "    def bottleneck(self, h):\n",
        "        #this function takes output of encoder and makes two different vectors - one for mu, one for variance\n",
        "        #result is then passed through reparametrize function\n",
        "        mu, logvar = self.fc1(h), self.fc2(h)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return z, mu, logvar\n",
        "\n",
        "    def encode(self, x):\n",
        "        h = self.encoder(x)\n",
        "        z, mu, logvar = self.bottleneck(h)\n",
        "        return z, mu, logvar\n",
        "\n",
        "    def decode(self, z):\n",
        "        z = self.fc3(z)\n",
        "        z = self.decoder(z)\n",
        "        return z\n",
        "\n",
        "    def forward(self, x):\n",
        "        z, mu, logvar = self.encode(x)\n",
        "        z = self.decode(z)\n",
        "        return z, mu, logvar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoFVoygAmNiQ",
        "outputId": "f109d2f0-c5b7-4940-fd78-550a67e5aaee"
      },
      "source": [
        "device = torch.device('cpu')\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzfqg-8Ei5p-"
      },
      "source": [
        "model = VAE().to(device)\n",
        "\n",
        "learning_rate = 1e-3\n",
        "optimizer = torch.optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=learning_rate,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zU0MXsOtlNcq"
      },
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    batch_losses = []\n",
        "    \n",
        "    for batch_idx, data in enumerate(train_loader):\n",
        "      data = data.to(device)\n",
        "      recon_images, mu, logvar = model(data)\n",
        "      loss, bce, kld = loss_function(recon_images, data, mu, logvar)\n",
        "      batch_losses.append(loss)\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      if batch_idx % 50 == 0:\n",
        "        print('Epoch {}, Batch {}'.format(epoch,batch_idx))\n",
        "\n",
        "        \n",
        "    epoch_loss = sum(batch_losses)/len(batch_losses)\n",
        "    \n",
        "    return(epoch_loss)\n",
        "\n",
        "def test(loader):\n",
        "  model.eval()\n",
        "  batch_losses = []\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    for batch_idx, (data, labels) in enumerate(loader):\n",
        "      recon_images, mu, logvar = model(data)\n",
        "      loss, bce, kld = loss_function(recon_images, data, mu, logvar)\n",
        "      \n",
        "      batch_losses.append(loss)\n",
        "    \n",
        "    epoch_loss = sum(batch_losses)/len(batch_losses)\n",
        "    return epoch_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "id": "FYRCWPmZli86",
        "outputId": "28acecd9-c01c-4d77-fbd6-2b5a56c8a8fc"
      },
      "source": [
        "epochs = []\n",
        "training_losses = []\n",
        "val_losses = []\n",
        "for epoch in range(10):\n",
        "  avg_train_loss = train(epoch)\n",
        "  print('Train loss for epoch {}: {}'.format(epoch, avg_train_loss))\n",
        "  val_loss = test(val_loader)\n",
        "  print('Val loss for epoch {}: {}'.format(epoch, val_loss))\n",
        "  epochs.append(epoch)\n",
        "  training_losses.append(avg_train_loss)\n",
        "  val_losses.append(val_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Input max: 255.0, Recon max: 0.5143575668334961\n",
            "Epoch 0, Batch 0\n",
            "Input max: 255.0, Recon max: nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-eabcf95f4e17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mval_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mavg_train_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train loss for epoch {}: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_train_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-a906e70da6c2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0mrecon_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkld\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecon_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m       \u001b[0mbatch_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-57b90209cb1f>\u001b[0m in \u001b[0;36mloss_function\u001b[0;34m(recon_x, x, mu, logvar)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecon_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input max: {}, Recon max: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecon_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mBCE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecon_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0;31m# BCE = F.mse_loss(recon_x, x, size_average=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2525\u001b[0m     return torch._C._nn.binary_cross_entropy(\n\u001b[0;32m-> 2526\u001b[0;31m         input, target, weight, reduction_enum)\n\u001b[0m\u001b[1;32m   2527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: all elements of input should be between 0 and 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8wXH11zIsu8"
      },
      "source": [
        "%debug"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Y9wAnjQWQEt"
      },
      "source": [
        "x = torch.randn((3,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YaEUWG6zXbQ"
      },
      "source": [
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8TaIpYSzaC9"
      },
      "source": [
        "torch.max(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0y8-sd-FzeGN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}